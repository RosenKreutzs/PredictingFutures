# 决策树(Treereg)
2024/5/20
## 决策树的训练目的
以先根据划分标准构建再根据对应指标剪枝的方式，获得每个节点的最优划分条件。(每个节点的最优划分条件:一般用一个节点对应一个特征，但可用多个特征)
## 深度森林的原稿

链接：https://pan.baidu.com/s/1AA2eh_FjwUX82Gka3QGL-g?pwd=92kl 
提取码：92kl 

## 决策树的训练流程也是构建流程

![Treereg的示例](/assets/Treereg的示例.png )

1. 决策树的构建：
   - 根节点的训练数据集A的元素数量sample为105个；
   - 根据划分标准entropy(例如增益率，信息增益，基尼指数等)对当前数据集A的所有特征与标签value进行计算，然后按结果划分为数据集B0，B1等；
   - 等B0，B1子数据集进行继续根据划分标准划分数据集，直到某一子数据集的标签都统一了，就停止对当前分支的划分；
   - 当所以分支都停止后，由划分标准对应划分条件(即不等式判断条件)为节点构成未剪枝的决策树；
2. 决策树的剪枝：（减少模型无用分支，类似于删除神经网络的无用参数一样）
   - 以验证数据集A，去计算父节点与子节点间过程对于结果准确度的提升为标准，来判断该子节点对应的分支是否应该剪掉；